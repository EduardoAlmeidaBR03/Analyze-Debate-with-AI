from flask import Flask, request, jsonify, render_template_string, send_from_directory
import requests
import google.generativeai as genai
import os
from dotenv import load_dotenv
import re
from urllib.parse import urlparse, parse_qs
from youtube_transcript_api import YouTubeTranscriptApi
# Novos imports para wordcloud
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import matplotlib
matplotlib.use('Agg')  
import io
import base64
from collections import Counter
import string

# Carregar vari√°veis de ambiente
load_dotenv()

app = Flask(__name__)

# Configurar Gemini AI
genai.configure(api_key=os.getenv('GEMINI_API_KEY'))
# Atualizar para o modelo mais recente
model = genai.GenerativeModel('gemini-1.5-flash')

def extract_video_id(youtube_url):
    """Extrai o ID do v√≠deo do YouTube da URL"""
    # Padr√µes comuns de URLs do YouTube
    patterns = [
        r'(?:youtube\.com\/watch\?v=|youtu\.be\/|youtube\.com\/embed\/)([^&\n?#]+)',
        r'youtube\.com\/watch\?.*v=([^&\n?#]+)'
    ]
    
    for pattern in patterns:
        match = re.search(pattern, youtube_url)
        if match:
            return match.group(1)
    
    return None

def get_transcript_from_youtube_api(video_id):
    """Obt√©m a transcri√ß√£o do v√≠deo usando a YouTube Transcript API"""
    try:
        # Tentar obter transcri√ß√£o em portugu√™s primeiro
        try:
            transcript_list = YouTubeTranscriptApi.get_transcript(video_id, languages=['pt', 'pt-BR'])
        except:
            # Se n√£o houver em portugu√™s, tentar em ingl√™s
            try:
                transcript_list = YouTubeTranscriptApi.get_transcript(video_id, languages=['en'])
            except:
                # Se n√£o houver em ingl√™s, pegar qualquer idioma dispon√≠vel
                transcript_list = YouTubeTranscriptApi.get_transcript(video_id)
        
        # Concatenar todas as partes da transcri√ß√£o
        full_transcript = ""
        for entry in transcript_list:
            full_transcript += entry['text'] + " "
        
        return full_transcript.strip()
        
    except Exception as e:
        print(f"Erro ao obter transcri√ß√£o da YouTube Transcript API: {e}")
        return None

def get_available_transcripts(video_id):
    """Obt√©m lista de idiomas dispon√≠veis para transcri√ß√£o"""
    try:
        transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)
        available_languages = []
        
        for transcript in transcript_list:
            available_languages.append({
                'language': transcript.language,
                'language_code': transcript.language_code,
                'is_generated': transcript.is_generated,
                'is_translatable': transcript.is_translatable
            })
        
        return available_languages
        
    except Exception as e:
        print(f"Erro ao listar transcri√ß√µes dispon√≠veis: {e}")
        return []

def get_youtube_info_alternative(youtube_url):
    """M√©todo alternativo para obter informa√ß√µes do YouTube usando m√∫ltiplas abordagens"""
    
    # Tentar primeiro com PyTube
    try:
        from pytube import YouTube
        print(f"Tentando PyTube para: {youtube_url}")
        
        yt = YouTube(youtube_url)
        
        if yt.title and yt.author:  # Se conseguiu obter as informa√ß√µes b√°sicas
            info = {
                'title': yt.title,
                'description': yt.description or 'Descri√ß√£o n√£o dispon√≠vel',
                'length': yt.length or 0,
                'views': yt.views or 0,
                'author': yt.author
            }
            print(f"PyTube funcionou: {info['title']}")
            return info
            
    except Exception as e:
        print(f"PyTube falhou: {e}")
    
    # M√©todo alternativo: extrair informa√ß√µes do HTML da p√°gina
    try:
        print("Tentando m√©todo alternativo (scraping)")
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        response = requests.get(youtube_url, headers=headers, timeout=10)
        html_content = response.text
        
        # Extrair t√≠tulo
        title_match = re.search(r'"title":"([^"]+)"', html_content)
        title = title_match.group(1) if title_match else "T√≠tulo n√£o dispon√≠vel"
        
        # Extrair autor/canal
        author_match = re.search(r'"author":"([^"]+)"', html_content) or re.search(r'"channelName":"([^"]+)"', html_content)
        author = author_match.group(1) if author_match else "Canal n√£o dispon√≠vel"
        
        # Extrair dura√ß√£o (em segundos)
        duration_match = re.search(r'"lengthSeconds":"(\d+)"', html_content)
        duration = int(duration_match.group(1)) if duration_match else 0
        
        # Extrair visualiza√ß√µes
        views_match = re.search(r'"viewCount":"(\d+)"', html_content)
        views = int(views_match.group(1)) if views_match else 0
        
        # Extrair descri√ß√£o
        desc_match = re.search(r'"shortDescription":"([^"]*)"', html_content)
        description = desc_match.group(1) if desc_match else "Descri√ß√£o n√£o dispon√≠vel"
        
        info = {
            'title': title,
            'description': description,
            'length': duration,
            'views': views,
            'author': author
        }
        
        print(f"Scraping funcionou: {info['title']}")
        return info
        
    except Exception as e:
        print(f"M√©todo alternativo falhou: {e}")
    
    # Se tudo falhar, retornar informa√ß√µes b√°sicas com base no ID do v√≠deo
    try:
        video_id = extract_video_id(youtube_url)
        return {
            'title': f'V√≠deo do YouTube (ID: {video_id})',
            'description': 'N√£o foi poss√≠vel obter a descri√ß√£o',
            'length': 0,
            'views': 0,
            'author': 'Canal n√£o identificado'
        }
    except:
        return {
            'title': 'V√≠deo do YouTube',
            'description': 'N√£o foi poss√≠vel obter informa√ß√µes',
            'length': 0,
            'views': 0,
            'author': 'Canal n√£o identificado'
        }

def analyze_with_gemini(transcript, video_info=None):
    """Analisa a transcri√ß√£o usando o Gemini AI"""
    try:
        prompt = f"""
        Analise o seguinte conte√∫do de v√≠deo do YouTube e forne√ßa uma an√°lise detalhada:

        {f"T√≠tulo: {video_info.get('title', 'N/A')}" if video_info else ""}
        {f"Autor: {video_info.get('author', 'N/A')}" if video_info else ""}
        {f"Descri√ß√£o: {video_info.get('description', 'N/A')}" if video_info else ""}

        Transcri√ß√£o/Conte√∫do:
        {transcript}

        Por favor, forne√ßa:
        1. Um resumo conciso do que foi discutido
        2. Elaborar uma an√°lise cr√≠tica dos pontos positivos das falas de Adriana
        3. . Elaborar uma an√°lise cr√≠tica dos pontos positivos das falas de Lodovico

        Responda em portugu√™s de forma estruturada e detalhada.
        """

        response = model.generate_content(prompt)
        return response.text

    except Exception as e:
        print(f"Erro ao analisar com Gemini: {e}")
        return f"Erro na an√°lise: {str(e)}"

def clean_text_for_wordcloud(text):
    """Limpa e processa o texto para gerar a nuvem de palavras"""
    if not text:
        return ""
    
    # Converter para min√∫sculas
    text = text.lower()
    
    # Remover pontua√ß√£o
    text = text.translate(str.maketrans('', '', string.punctuation))
    
    # Remover n√∫meros
    text = re.sub(r'\d+', '', text)
    
    # Remover palavras muito comuns em portugu√™s (stop words)
    stop_words = {
        'm√∫sica','o', 'a', 'os', 'as', 'um', 'uma', 'uns', 'umas', 'de', 'do', 'da', 'dos', 'das',
        'para', 'por', 'com', 'em', 'no', 'na', 'nos', 'nas', 'e', 'ou', 'mas', 'que',
        'se', 'n√£o', 'eu', 'tu', 'ele', 'ela', 'n√≥s', 'v√≥s', 'eles', 'elas', 'meu',
        'minha', 'meus', 'minhas', 'seu', 'sua', 'seus', 'suas', 'nosso', 'nossa',
        'nossos', 'nossas', 'este', 'esta', 'estes', 'estas', 'esse', 'essa', 'esses',
        'essas', 'aquele', 'aquela', 'aqueles', 'aquelas', 'como', 'quando', 'onde',
        'porque', 'quanto', 'qual', 'quais', 'quem', 'muito', 'mais', 'menos', 'bem',
        'j√°', 'ainda', 's√≥', 'tamb√©m', 'at√©', 'ent√£o', 'sobre', 'depois', 'antes',
        'aqui', 'ali', 'l√°', 'sim', 'a√≠', 'n√©', 't√°', 'vai', '√©', 'ser', 'estar',
        'ter', 'haver', 'fazer', 'ver', 'dar', 'dizer', 'ir', 'vir', 'saber', 'poder'
    }
    
    # Dividir em palavras e filtrar
    words = text.split()
    filtered_words = [word for word in words if len(word) > 2 and word not in stop_words]
    
    return ' '.join(filtered_words)

def extract_speaker_text(transcript, speaker_name):
    """Extrai o texto falado por um participante espec√≠fico"""
    if not transcript or not speaker_name:
        return ""
    
    # Padr√µes para identificar falas do participante
    patterns = [
        rf'{re.escape(speaker_name)}\s*:(.+?)(?={re.escape("Adriana")}|{re.escape("Lodovico")}|\Z)',
        rf'{re.escape(speaker_name)}\s+(.+?)(?={re.escape("Adriana")}|{re.escape("Lodovico")}|\Z)',
        rf'{re.escape(speaker_name)}(.+?)(?={re.escape("Adriana")}|{re.escape("Lodovico")}|\Z)'
    ]
    
    speaker_text = ""
    
    # Tentar diferentes padr√µes para extrair as falas
    for pattern in patterns:
        matches = re.findall(pattern, transcript, re.IGNORECASE | re.DOTALL)
        if matches:
            speaker_text = " ".join(matches).strip()
            break
    
    # Se n√£o encontrar padr√µes espec√≠ficos, tentar busca por contexto
    if not speaker_text:
        # Dividir o texto em par√°grafos/se√ß√µes
        sections = re.split(r'\n+', transcript)
        for section in sections:
            if speaker_name.lower() in section.lower():
                # Extrair texto ap√≥s o nome do participante
                speaker_match = re.search(rf'{re.escape(speaker_name)}\s*:?\s*(.+)', section, re.IGNORECASE)
                if speaker_match:
                    speaker_text += " " + speaker_match.group(1)
    
    return speaker_text.strip()

def generate_wordcloud(text, colormap='viridis', title_suffix=""):
    """Gera uma nuvem de palavras e retorna como base64"""
    try:
        # Limpar o texto
        clean_text = clean_text_for_wordcloud(text)
        
        if not clean_text:
            return None, []
        
        # Contar frequ√™ncia das palavras
        words = clean_text.split()
        word_freq = Counter(words)
        
        # Pegar as 50 palavras mais comuns
        top_words = word_freq.most_common(50)
        
        # Criar a nuvem de palavras
        wordcloud = WordCloud(
            width=800, 
            height=400,
            background_color='white',
            max_words=50,
            colormap=colormap,
            relative_scaling=0.5,
            random_state=42
        ).generate(clean_text)
        
        # Salvar como imagem em mem√≥ria
        plt.figure(figsize=(10, 5))
        plt.imshow(wordcloud, interpolation='bilinear')
        plt.axis('off')
        
        # Adicionar t√≠tulo se fornecido
        if title_suffix:
            plt.title(f'Nuvem de Palavras - {title_suffix}', fontsize=16, pad=20)
        
        # Converter para base64
        img_buffer = io.BytesIO()
        plt.savefig(img_buffer, format='png', bbox_inches='tight', 
                   dpi=150, facecolor='white', edgecolor='none')
        img_buffer.seek(0)
        
        img_str = base64.b64encode(img_buffer.getvalue()).decode()
        plt.close()  # Liberar mem√≥ria
        
        return img_str, top_words
        
    except Exception as e:
        print(f"Erro ao gerar nuvem de palavras: {e}")
        return None, []

def generate_speaker_wordclouds(transcript):
    """Gera nuvens de palavras separadas para Adriana e Lodovico"""
    wordclouds = {}
    
    # Extrair texto de cada participante
    adriana_text = extract_speaker_text(transcript, "Adriana")
    lodovico_text = extract_speaker_text(transcript, "Lodovico")
    
    print(f"Texto extra√≠do da Adriana: {len(adriana_text)} caracteres")
    print(f"Texto extra√≠do do Lodovico: {len(lodovico_text)} caracteres")
    
    # Gerar nuvem de palavras para Adriana
    if adriana_text:
        adriana_wordcloud, adriana_freq = generate_wordcloud(
            adriana_text, 
            colormap='Reds', 
            title_suffix="Adriana"
        )
        if adriana_wordcloud:
            wordclouds['adriana'] = {
                'image': adriana_wordcloud,
                'word_frequencies': adriana_freq,
                'text_length': len(adriana_text)
            }
    
    # Gerar nuvem de palavras para Lodovico
    if lodovico_text:
        lodovico_wordcloud, lodovico_freq = generate_wordcloud(
            lodovico_text, 
            colormap='Blues', 
            title_suffix="Lodovico"
        )
        if lodovico_wordcloud:
            wordclouds['lodovico'] = {
                'image': lodovico_wordcloud,
                'word_frequencies': lodovico_freq,
                'text_length': len(lodovico_text)
            }
    
    return wordclouds

@app.route('/analyze-youtube', methods=['POST', 'GET'])
def analyze_youtube_video():
    """Endpoint principal para analisar v√≠deos do YouTube"""
    
    # Se for GET, mostrar formul√°rio de exemplo
    if request.method == 'GET':
        return jsonify({
            'message': 'Endpoint para an√°lise de v√≠deos do YouTube',
            'method': 'POST',
            'content_type': 'application/json',
            'example_body': {
                'youtube_url': 'https://www.youtube.com/watch?v=VIDEO_ID'
            },
            'usage': 'Envie uma requisi√ß√£o POST com a URL do YouTube no body JSON',
            'transcript_source': 'YouTube Transcript API'
        })
    
    try:
        data = request.get_json()
        
        if not data or 'youtube_url' not in data:
            return jsonify({
                'error': 'URL do YouTube √© obrigat√≥ria',
                'status': 'error',
                'example': {
                    'youtube_url': 'https://www.youtube.com/watch?v=VIDEO_ID'
                }
            }), 400

        youtube_url = data['youtube_url']
        
        # Validar URL do YouTube
        video_id = extract_video_id(youtube_url)
        if not video_id:
            return jsonify({
                'error': 'URL do YouTube inv√°lida',
                'status': 'error',
                'received_url': youtube_url
            }), 400

        # Obter informa√ß√µes do v√≠deo
        video_info = get_youtube_info_alternative(youtube_url)
        
        # Obter lista de idiomas dispon√≠veis para transcri√ß√£o
        available_transcripts = get_available_transcripts(video_id)
        
        # Tentar obter transcri√ß√£o usando YouTube Transcript API
        transcript = get_transcript_from_youtube_api(video_id)
        
        transcript_source = 'youtube_transcript_api'
        
        # Se n√£o conseguir transcri√ß√£o, usar descri√ß√£o do YouTube como fallback
        if not transcript and video_info and video_info.get('description'):
            transcript = video_info['description']
            transcript_source = 'youtube_description'
        elif not transcript:
            return jsonify({
                'error': 'N√£o foi poss√≠vel obter transcri√ß√£o ou descri√ß√£o do v√≠deo',
                'status': 'error',
                'video_info': video_info,
                'available_transcripts': available_transcripts,
                'message': 'Este v√≠deo pode n√£o ter legendas/transcri√ß√£o dispon√≠vel'
            }), 400

        # Analisar com Gemini
        analysis = analyze_with_gemini(transcript, video_info)
        
        # Gerar nuvem de palavras geral
        wordcloud_img, word_frequencies = generate_wordcloud(transcript, 'viridis', 'Geral')
        
        # Gerar nuvens de palavras por participante
        speaker_wordclouds = generate_speaker_wordclouds(transcript)

        return jsonify({
            'status': 'success',
            'video_info': video_info,
            'transcript_source': transcript_source,
            'available_transcripts': available_transcripts,
            'transcript_length': len(transcript),
            'transcript': transcript,  # Adicionando a transcri√ß√£o na resposta
            'analysis': analysis,
            'video_id': video_id,
            'wordcloud': wordcloud_img,  # Imagem da nuvem de palavras geral em base64
            'word_frequencies': word_frequencies,  # Lista das palavras mais frequentes gerais
            'speaker_wordclouds': speaker_wordclouds  # Nuvens de palavras por participante
        })

    except Exception as e:
        return jsonify({
            'error': f'Erro interno: {str(e)}',
            'status': 'error'
        }), 500

@app.route('/transcript-only/<video_id>', methods=['GET'])
def get_transcript_only(video_id):
    """Endpoint para obter apenas a transcri√ß√£o de um v√≠deo"""
    try:
        # Obter transcri√ß√£o
        transcript = get_transcript_from_youtube_api(video_id)
        available_transcripts = get_available_transcripts(video_id)
        
        if not transcript:
            return jsonify({
                'error': 'Transcri√ß√£o n√£o dispon√≠vel para este v√≠deo',
                'status': 'error',
                'video_id': video_id,
                'available_transcripts': available_transcripts
            }), 404
        
        return jsonify({
            'status': 'success',
            'video_id': video_id,
            'transcript': transcript,
            'transcript_length': len(transcript),
            'available_transcripts': available_transcripts
        })
        
    except Exception as e:
        return jsonify({
            'error': f'Erro ao obter transcri√ß√£o: {str(e)}',
            'status': 'error'
        }), 500

@app.route('/health', methods=['GET'])
def health_check():
    """Endpoint de verifica√ß√£o de sa√∫de da API"""
    return jsonify({
        'status': 'healthy',
        'message': 'API de an√°lise de v√≠deos do YouTube est√° funcionando',
        'transcript_method': 'YouTube Transcript API',
        'endpoints': {
            '/': 'GET - Informa√ß√µes da API',
            '/analyze-youtube': 'POST - Analisar v√≠deo do YouTube',
            '/transcript-only/<video_id>': 'GET - Obter apenas transcri√ß√£o',
            '/wordcloud/<video_id>': 'GET - Gerar nuvem de palavras',
            '/health': 'GET - Status da API',
            '/frontend': 'GET - Interface web'
        }
    })

@app.route('/frontend')
def frontend():
    """Serve the frontend HTML page"""
    with open('index.html', 'r', encoding='utf-8') as file:
        return file.read()

@app.route('/static/<path:filename>')
def static_files(filename):
    """Serve static files if needed"""
    return send_from_directory('static', filename)

@app.route('/', methods=['GET'])
def home():
    """Endpoint raiz com instru√ß√µes de uso"""
    return jsonify({
        'message': 'API de An√°lise de V√≠deos do YouTube',
        'version': '2.0',
        'transcript_method': 'YouTube Transcript API',
        'endpoints': {
            '/analyze-youtube': {
                'method': 'POST',
                'description': 'Analisa um v√≠deo do YouTube',
                'body': {
                    'youtube_url': 'URL do v√≠deo do YouTube'
                }
            },
            '/transcript-only/<video_id>': {
                'method': 'GET',
                'description': 'Obt√©m apenas a transcri√ß√£o de um v√≠deo',
                'example': '/transcript-only/dQw4w9WgXcQ'
            },
            '/wordcloud/<video_id>': {
                'method': 'GET',
                'description': 'Gera nuvem de palavras de um v√≠deo',
                'example': '/wordcloud/dQw4w9WgXcQ'
            },
            '/health': {
                'method': 'GET', 
                'description': 'Verifica status da API'
            },
            '/frontend': {
                'method': 'GET',
                'description': 'Interface web para an√°lise de v√≠deos'
            }
        },
        'example_usage': {
            'url': 'http://localhost:5000/analyze-youtube',
            'method': 'POST',
            'headers': {
                'Content-Type': 'application/json'
            },
            'body': {
                'youtube_url': 'https://www.youtube.com/watch?v=dQw4w9WgXcQ'
            }
        }
    })

@app.errorhandler(404)
def not_found(error):
    return jsonify({
        'error': 'Endpoint n√£o encontrado',
        'available_endpoints': [
            '/',
            '/analyze-youtube',
            '/health',
            '/frontend'
        ]
    }), 404

@app.errorhandler(405)
def method_not_allowed(error):
    return jsonify({
        'error': 'M√©todo n√£o permitido',
        'message': 'Verifique o m√©todo HTTP e endpoint corretos',
        'endpoints': {
            '/': ['GET'],
            '/analyze-youtube': ['POST', 'GET'],
            '/health': ['GET'],
            '/frontend': ['GET']
        }
    }), 405

@app.route('/wordcloud/<video_id>', methods=['GET'])
def generate_wordcloud_only(video_id):
    """Endpoint para gerar apenas a nuvem de palavras de um v√≠deo"""
    try:
        # Obter transcri√ß√£o
        transcript = get_transcript_from_youtube_api(video_id)
        
        if not transcript:
            return jsonify({
                'error': 'Transcri√ß√£o n√£o dispon√≠vel para este v√≠deo',
                'status': 'error',
                'video_id': video_id
            }), 404
        
        # Gerar nuvem de palavras
        wordcloud_img, word_frequencies = generate_wordcloud(transcript)
        
        if not wordcloud_img:
            return jsonify({
                'error': 'N√£o foi poss√≠vel gerar a nuvem de palavras',
                'status': 'error',
                'video_id': video_id
            }), 500
        
        return jsonify({
            'status': 'success',
            'video_id': video_id,
            'wordcloud': wordcloud_img,
            'word_frequencies': word_frequencies,
            'total_words': len(word_frequencies)
        })
        
    except Exception as e:
        return jsonify({
            'error': f'Erro ao gerar nuvem de palavras: {str(e)}',
            'status': 'error'
        }), 500

if __name__ == '__main__':
    print("üöÄ Iniciando API de An√°lise de V√≠deos do YouTube...")
    print("üìç Endpoints dispon√≠veis:")
    print("   GET  / - Informa√ß√µes da API")
    print("   GET  /frontend - Interface web")
    print("   POST /analyze-youtube - Analisar v√≠deo")
    print("   GET  /health - Status da API")
    print("üåê Acesse a interface em: http://localhost:5000/frontend")
    app.run(debug=True, host='0.0.0.0', port=5000)